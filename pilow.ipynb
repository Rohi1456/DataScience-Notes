{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IPL.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFDuwldjfGP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Image processing library"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SKmrhl3fOWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0oxbX_gfP2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\" IPL version \",PIL.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDO8I48-fcpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load and show Image with pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AMLbfB0f_4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "#Load the Image\n",
        "image  = Image.open('Sydney-Opera-House.jpg')\n",
        "#Summarize some details of the image\n",
        "print(image.format)\n",
        "print(image.mode)\n",
        "print(image.size)\n",
        "#show Image\n",
        "image.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXwiKkOAgCDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert Images to NumpyArray and Back"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zMkJ6HAgvOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load and display images with matplotlib\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "data = image.imread('Sydney-Opera-House.jpg')\n",
        "#Summarize shape of the pixel array\n",
        "print(data.dtype)\n",
        "print(data.shape)\n",
        "#display the array of pixels as an image\n",
        "pyplot.imshow(data)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX9epYiQhpvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The example below loads the photo as a Pillow Image object and\n",
        "#converts it to a NumPy array, then converts it back to an Image object again.\n",
        "# load image and convert to and from NumPy array\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "#load the image\n",
        "image = Image.open(\"Sydney-Opera-House.jpg\")\n",
        "#convert image to numpy array\n",
        "data = asarray(image)\n",
        "#Summarize the shape\n",
        "print(data.shape)\n",
        "#create pillow image\n",
        "image2 = Image.fromarray(data)  \n",
        "#Summarize image details\n",
        "print(image2.format)\n",
        "print(image2.mode)\n",
        "print(image2.size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP-cKCjuox-L",
        "colab_type": "text"
      },
      "source": [
        "**Load All Images In Directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3Zk7oGtowoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load all images in a directory\n",
        "from os import listdir\n",
        "from matplotlib import image\n",
        "# load all images in a directory\n",
        "loaded_images = list()\n",
        "for filename in listdir( \" images \" ):\n",
        " # load image\n",
        " img_data = image.imread( \"images/ \" + filename)\n",
        "# store loaded image\n",
        " loaded_images.append(img_data)\n",
        " print( \" > loaded %s %s \" % (filename, img_data.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kn9cBqktGSh",
        "colab_type": "text"
      },
      "source": [
        "**How to Save Images to File**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwr3vrrXnAwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of saving an image in another format\n",
        "from PIL import Image\n",
        "#Load the image\n",
        "image  = Image.open('Sydney-Opera-House.jpg')\n",
        "#saving as png format\n",
        "image.save('Opera-house.png',format = 'PNG')\n",
        "#load the image again and inspect the format\n",
        "image2 = Image.open('Opera-house.png')\n",
        "print(image2.format)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJrfpQHDue_I",
        "colab_type": "text"
      },
      "source": [
        "**There are a\n",
        "number of ways to convert an image to grayscale, but Pillow provides the convert() function\n",
        "and the mode ‘L’ will convert an image to grayscale.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQQIIRNokMnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of saving a grayscale image of loaded image\n",
        "from PIL import Image\n",
        "#load the iamge \n",
        "image = Image.open('Sydney-Opera-House.jpg')\n",
        "#convert image to grayscale\n",
        "gs_image = image.convert(mode='L')\n",
        "#save in jpeg format\n",
        "gs_image.save('Opera_gray_scale.jpg')\n",
        "#load the image and show it\n",
        "image2 = Image.open('Opera_gray_scale.jpg')\n",
        "pyplot.imshow(image2)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fItcpc4CvmWW",
        "colab_type": "text"
      },
      "source": [
        "**How to Resize Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmkRU655vJ-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a thumbanial of an image\n",
        "from PIL import Image\n",
        "#load the image\n",
        "image = Image.open('Sydney-Opera-House.jpg')\n",
        "print(image.size)\n",
        "pyplot.imshow(image)\n",
        "pyplot.show()\n",
        "#create a thumbanail and preserve aspect ratio\n",
        "image.thumbnail((100,100))\n",
        "#report the size of modified image\n",
        "print(image.size)\n",
        "#SHOW the image\n",
        "pyplot.imshow(image)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPx_NhoN6MZ9",
        "colab_type": "text"
      },
      "source": [
        "We may not want to preserve the aspect ratio, and instead, we may want to force the pixels\n",
        "into a new shape. This can be achieved using the resize() function that allows you to specify\n",
        "the width and height in pixels and the image will be reduced or stretched to fit the new shape.\n",
        "The example below demonstrates how to resize a new image and ignore the original aspect ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laCd8oRD5ZZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a thumbanial of an image\n",
        "from PIL import Image\n",
        "#load the image\n",
        "image = Image.open('Sydney-Opera-House.jpg')\n",
        "print(image.size)\n",
        "pyplot.imshow(image)\n",
        "pyplot.show()\n",
        "# resize image and ignore original aspect ratio\n",
        "image_resize = image.resize((200,200))\n",
        "#report the size of modified image\n",
        "print(image_resize.size)\n",
        "#SHOW the image\n",
        "pyplot.imshow(image_resize)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjcSSeHi7KB1",
        "colab_type": "text"
      },
      "source": [
        "**How to Flip, Rotate, and Crop Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4eTqhXc6YyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create flipped versions of an image\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "#load image\n",
        "image   = Image.open('Sydney-Opera-House.jpg')\n",
        "#horizontal flip\n",
        "hoz_flip = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "#verticala flip\n",
        "vertical_flip = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "#plot all three images using matplotlib\n",
        "pyplot.subplot(311)\n",
        "pyplot.imshow(image)\n",
        "pyplot.subplot(312)\n",
        "pyplot.imshow(hoz_flip)\n",
        "pyplot.subplot(313)\n",
        "pyplot.imshow(vertical_flip)\n",
        "pyplot.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewuOq01c-4bn",
        "colab_type": "text"
      },
      "source": [
        "**An image can be rotated using the rotate() function and passing in the angle for the rotation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWuzHrq990r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create rotate version of iamges\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "#load image\n",
        "image  = Image.open('Sydney-Opera-House.jpg')\n",
        "#plot original image\n",
        "pyplot.subplot(311)\n",
        "pyplot.imshow(image)\n",
        "#rotate 45 degrees\n",
        "pyplot.subplot(312)\n",
        "pyplot.imshow(image.rotate(45))\n",
        "#rotate 90 degrees\n",
        "pyplot.subplot(313)\n",
        "pyplot.imshow(image.rotate(90))\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5LXUU3fAHAC",
        "colab_type": "text"
      },
      "source": [
        "**Cropped Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXCCHO9I_mma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of cropping image\n",
        "from PIL import Image\n",
        "#load image\n",
        "image  = Image.open('Sydney-Opera-House.jpg')\\\n",
        "#create cropped image\n",
        "crop_image = image.crop((100,100,200,200))\n",
        "pyplot.imshow(crop_image)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu95hiKuL86M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load and show image with pillow\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot \n",
        "image = Image.open('sydney_bridge.png')\n",
        "print(image.mode)\n",
        "print(image.format)\n",
        "print(image.size)\n",
        "pyplot.imshow(image)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYGjKyeKkSlS",
        "colab_type": "text"
      },
      "source": [
        "**Normalize pixel values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNvkym3YjWn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for most images pixel values are in range 0 to255\n",
        "# neural n/w process the i/p using small weights.\n",
        "#as such larger inputs with small wegihts can disrupt the process and slow down the learning process.\n",
        "#so its bettre to normalize the pixel values to (0-1) instead (0-255)\n",
        "#can normlize by dividing all pixel values by large number in pixel values(255)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIRHCJwWnVCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normlaize example\n",
        "from numpy import asarray\n",
        "from PIL  import Image\n",
        "#load image\n",
        "image  = Image.open('sydney_bridge.png')\n",
        "pixels = asarray(image)\n",
        "#confirm pixel range is 0-255\n",
        "print(\"Data type :%s\" % pixels.dtype)\n",
        "print(\"pixel min: %3f,Max: pixel Max: %3f\" %(pixels.min(),pixels.max()))\n",
        "#convert from integers to float\n",
        "pixels = pixels.astype('float32')\n",
        "#normalize the 0-1\n",
        "pixels /= 255.0\n",
        "#confirm the normalization\n",
        "print(\"pixel min: %3f,Max: pixel Max: %3f\" %(pixels.min(),pixels.max()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK136CHzojw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Centering is two types \n",
        "#1)Global Centering\n",
        "#2)Local Centering\n",
        "#Cnetering can be performed before normalization or after normalization\n",
        "#but performing centering before normalization is better\n",
        "#if we perform cenralization after normalization pixels- (0-1)\n",
        "#if we perform centralization after normlaization pixels will be having both postive and negitives values.\n",
        "#pixels having both postitve and negitive values image can't be viewd.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql2bMPgMo6jN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of global centering (subtracting the mean)\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "#load image\n",
        "image= Image.open('sydney_bridge.png')\n",
        "pixels = asarray(image)\n",
        "#convert from integers to float\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate global mean\n",
        "mean = pixels.mean()\n",
        "print(\"pixels mean: %3f\" % mean)\n",
        "print(\"pixel min: %3f,Max: pixel Max: %3f\" %(pixels.min(),pixels.max()))\n",
        "#global centring of pixels\n",
        "pixels = pixels-mean\n",
        "# confirm it had the desired effect\n",
        "mean = pixels.mean()\n",
        "print( \" Mean: %.3f \" % mean)\n",
        "print( \" Min: %.3f, Max: %.3f \" % (pixels.min(), pixels.max()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdy4EaiKwBky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#global centring mean as mean 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ReWEONFHhX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The example below calculates the mean for each color channel in the loaded image, then\n",
        "#centers the pixel values for each channel separately"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVfEYUTCHvGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of perchannle centering(saubstract mean)\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "#load image\n",
        "image = Image.open('sydney_bridge.png')\n",
        "pixels = asarray(image)\n",
        "#convert integer to float\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate per-channels mean and std.\n",
        "means = pixels.mean(axis=(0,1),dtype='float64')\n",
        "print(image.size)\n",
        "print(\"Means: %s\"% means)\n",
        "print(\"Means Min : %s, Means Max: %s\"% (pixels.min(axis=(0,1)),pixels.max(axis=(0,1))))\n",
        "#per channel centering of pixels\n",
        "pixels -=means\n",
        "#confirm it has desired effect\n",
        "means = pixels.mean(axis=(0,1), dtype= 'float64' )\n",
        "print(\" Means: %s \" % means)\n",
        "print( \"Mins: %s, Maxs: %s \" % (pixels.min(axis=(0,1)), pixels.max(axis=(0,1))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5klEexh6OC3h",
        "colab_type": "text"
      },
      "source": [
        "**Global Standardization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPck0hqNIk3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of global pixel standardization\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "#load image\n",
        "image = Image.open('sydney_bridge.png')\n",
        "pixels = asarray(image)\n",
        "#convert integer to float\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate global mean ans std\n",
        "mean,std = pixels.mean(),pixels.std()\n",
        "print(\"Mean %3f,  std : %3f\"%(mean,std))\n",
        "#global standardization  of pixels\n",
        "pixels = (pixels-mean)/std\n",
        "#confirm it has desireed effect\n",
        "mean,std = pixels.mean(),pixels.std() #it should give mean as 0 and std as 1\n",
        "print(\"Mean %3f,  std : %3f\"%(mean,std))\n",
        "print( \" Min: %.3f, Max: %.3f \" % (pixels.min(), pixels.max()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNFvCMB_PfwC",
        "colab_type": "text"
      },
      "source": [
        "**Positive Global Standardization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXXuBnVcIsAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if we want maintain pixel values positve\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlFsF_5gXRP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of global pixel stadardization to positive domain\n",
        "from numpy import asarray\n",
        "from numpy import clip\n",
        "from PIL import Image\n",
        "#load image\n",
        "image = Image.open('sydney_bridge.png')\n",
        "pixels =asarray(image)\n",
        "pixels = pixels.astype('float32')\n",
        "#calculate global mean and std\n",
        "mean,std = pixels.mean(),pixels.std()\n",
        "print(\"Mean: %3f, StD : %3f\" %(mean,std))\n",
        "#global standardization of pixels\n",
        "pixels = (pixels-mean)/std\n",
        "#clip pixel values to [-1,1]\n",
        "pixels = clip(pixels,-1.0,1.0)\n",
        "#shift ftom [-1,1] to   [0,1] with 0.5 mean\n",
        "pixels  = (pixels+1.0)/2.0\n",
        "# confirm it had the desired effect\n",
        "mean, std = pixels.mean(), pixels.std()\n",
        "print(\"Mean: %3f, StD : %3f\" %(mean,std))\n",
        "print(\"Min: %3f, Max : %3f\" %(pixels.min(),pixels.max()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_Soy0hZiYz",
        "colab_type": "text"
      },
      "source": [
        "**Local Standardization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae3CI3XDYERy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#local standardization calculate per each channel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6gM8175rHGb",
        "colab_type": "text"
      },
      "source": [
        "**How to Load and Manipulate Images\n",
        "with Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB04pudpZpU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of loading an image with keras api\n",
        "from keras.preprocessing.image import load_img\n",
        "#load the image\n",
        "img = load_img('beach.jpg')\n",
        "#report details about the image\n",
        "print(type(img))\n",
        "print(img.format)\n",
        "print(img.size)\n",
        "print(img.mode)\n",
        "#show the image\n",
        "pyplot.imshow(img)\n",
        "pyplot.show()\n",
        "#img.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1Q2d_47sgHR",
        "colab_type": "text"
      },
      "source": [
        "Keras provides the **img to array()**function for converting a loaded image in PIL format into\n",
        "a NumPy array for use with deep learning models. The API also provides the **array to img()**\n",
        "function that can be used for converting a NumPy array of pixel data into a PIL image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1PwEnWvr4oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of an image converting an image with keras API.\n",
        "from keras.preprocessing.image import  load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import  array_to_img\n",
        "#load the image\n",
        "img = load_img('beach.jpg')\n",
        "print(type(img))\n",
        "#convert numpy array\n",
        "img_array = img_to_array(img)\n",
        "print(type(img_array))\n",
        "print(img_array.shape)\n",
        "#convert back to iamge\n",
        "img = array_to_img(img_array)\n",
        "print(type(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3iWLl5s0pa_",
        "colab_type": "text"
      },
      "source": [
        "**How To save an image with keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNyR_G-QtT81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of saving an image with keras api\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras.preprocessing.image  import img_to_array\n",
        "#load image as grayscale\n",
        "img = load_img(\"beach.jpg\",color_mode='grayscale')\n",
        "#convert image to numpy array\n",
        "img_array = img_to_array(img)\n",
        "#save the image with new filename\n",
        "save_img('beach_gray.jpg',img_array)\n",
        "#load the image  to confirm it saves correctly\n",
        "img = load_img('beach_gray.jpg')\n",
        "print(type(img))\n",
        "print(img.mode)\n",
        "print(img.format)\n",
        "print(img.size)\n",
        "pyplot.imshow(img)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXEx6nYh4YoW",
        "colab_type": "text"
      },
      "source": [
        "**how to scale image pixel data with keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1dk4WbQ11ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of loading the mnist dataset\n",
        "from keras.datasets  import mnist\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MNODMqJeXv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of loading the mnist dataset\n",
        "from keras.datasets  import mnist\n",
        "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()\n",
        "#summarize the datasets shape\n",
        "print(\"Train\",train_images.shape,train_labels.shape)\n",
        "print(\"Test\",test_images.shape,test_labels.shape)\n",
        "#Summarize pixel values\n",
        "print('Train',train_images.min(),train_images.max(),train_images.mean(),train_images.std())\n",
        "print('Test',test_images.min(),test_images.max(),test_images.mean(),test_images.std())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwA-WSRof_s7",
        "colab_type": "text"
      },
      "source": [
        "**ImageDataGenerator Class for Pixel Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB4Klycgenbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example of normalizing images data set\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#load dataset\n",
        "(trainX,trainY),(testX,testY) = mnist.load_data()\n",
        "#reshape data set to have a single channel\n",
        "print(\"TrainX shpae\",trainX.shape)\n",
        "print(\"TestX shpae\",testX.shape)\n",
        "#channle mean no.of colors rgb(3) or gray(1)\n",
        "width,height,channels = trainX.shape[1],trainX.shape[2],1\n",
        "trainX = trainX.reshape(trainX.shape[0],width,height,1)\n",
        "testX = testX.reshape(testX.shape[0],width,height,1)\n",
        "print(\"TrainX shpae\",trainX.shape)\n",
        "print(\"TestX shpae\",testX.shape)\n",
        "print(\"channel 1 mean gray scale images\")\n",
        "#Confirm scale of pixels\n",
        "print(\"Train Min : %3f, max : %3f\" % (trainX.min(),trainX.max()))\n",
        "print(\"Test Min : %3f, max : %3f\" % (testX.min(),testX.max()))\n",
        "# create generator (1.0/255.0 = 0.003921568627451)\n",
        "datagen = ImageDataGenerator(rescale= 1.0/255.0)\n",
        "# Note: there is no need to fit the generator in this case\n",
        "# prepare a iterators to scale images\n",
        "train_iterator = datagen.flow(trainX,trainY,batch_size=64)\n",
        "test_iterator = datagen.flow(testX,testY,batch_size = 64)\n",
        "print('Batches Train= %d , Test = %d'% (len(train_iterator),len(test_iterator)))\n",
        "#confirm scaling works\n",
        "batchX,batchY =  train_iterator.next()\n",
        "print( \"Batch shape=%s, min=%.3f, max=%.3f \" % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51LRTl515UGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Center images with iamge data generator\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#load data set\n",
        "(trainX,trainY),(testX,testY) = mnist.load_data()\n",
        "#reshape data to having a single channel\n",
        "width,height,channels = trainX.shape[1],trainX.shape[2],1\n",
        "trainX = trainX.reshape(trainX.shape[0],width,height,channels)\n",
        "testX = testX.reshape(testX.shape[0],width,height,channels)\n",
        "#report per Image mean\n",
        "print(\"Measn train = %.3f, test %.3f\"% (trainX.mean(),testX.mean()))\n",
        "#create a generator that centeres pixels values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print(\"DataGenerator mean : %3f\" %datagen.mean)\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX,trainY,batch_size=64)\n",
        "#get a batch\n",
        "batchX,batchY = iterator.next()\n",
        "#mean pixel value in th batch\n",
        "print(batchX.shape,batchX.mean())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ry3bEpLch0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#standard normalization\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#load data set\n",
        "(trainX,trainY),(testX,testY) = mnist.load_data()\n",
        "#reshape data to having a single channel\n",
        "width,height,channels = trainX.shape[1],trainX.shape[2],1\n",
        "trainX = trainX.reshape(trainX.shape[0],width,height,channels)\n",
        "testX = testX.reshape(testX.shape[0],width,height,channels)\n",
        "#report per Image mean\n",
        "print(\"Measn train = %.3f, test %.3f\"% (trainX.mean(),testX.mean()))\n",
        "#create a generator that centeres pixels values\n",
        "datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print(\"DataGenerator mean : %3f std : %3f\" % (datagen.mean,datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX,trainY,batch_size=64)\n",
        "#get a batch\n",
        "batchX,batchY = iterator.next()\n",
        "#mean pixel value in th batch\n",
        "print(batchX.shape,batchX.mean(),batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape,batchX.std(), batchX.mean())\n",
        "#mean 0 std 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH0gcqxfSyJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBE3YMJz75Vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}